{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a CNN audio classifier using melspectograms from Audioset and ESC-50 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17070039307598391372\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15559258932\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 10869534684202922379\n",
      "physical_device_desc: \"device: 0, name: Quadro P5000, pci bus id: 0000:00:05.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(file_paths, label_dir, train_split):\n",
    "    # get new train and validation indices\n",
    "    n_files = len(file_paths)\n",
    "    n_train = int(train_split * n_files)\n",
    "    train_idx = random.sample(range(n_files), n_train)\n",
    "    val_idx = list(set(range(n_files)) - set(train_idx))\n",
    "    \n",
    "    # split files\n",
    "    train_set = [file_paths[idx] for idx in train_idx]\n",
    "    val_set = [file_paths[idx] for idx in val_idx]\n",
    "\n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and save train and validation splits into tmp directories\n",
    "def train_and_val_split(path_to_train_set, train_split, seed=23):\n",
    "    random.seed(seed)\n",
    "\n",
    "    train_labels = os.listdir(path_to_train_set)\n",
    "    print '{} classes observed'.format(len(train_labels))\n",
    "    \n",
    "    # split original files\n",
    "    train_dir = '/tmp/train'\n",
    "    val_dir = '/tmp/val'\n",
    "    n_train_files = 0\n",
    "    n_val_files = 0\n",
    "    for label_dir in train_labels:\n",
    "        # fill in dictionary\n",
    "        full_path_to_dir = os.path.join(path_to_train_set, label_dir)\n",
    "        files = os.listdir(full_path_to_dir) \n",
    "        file_paths = [os.path.join(path_to_train_set, label_dir, f) for f in files]\n",
    "        train_set, val_set = split_dataset(file_paths, label_dir, train_split)\n",
    "        \n",
    "        # copy files over to tmp directories\n",
    "        train_label_dir = os.path.join(train_dir, label_dir)\n",
    "        if os.path.exists(train_label_dir):\n",
    "            shutil.rmtree(train_label_dir)\n",
    "        os.makedirs(train_label_dir)\n",
    "            \n",
    "        val_label_dir = os.path.join(val_dir, label_dir)\n",
    "        if os.path.exists(val_label_dir):\n",
    "            shutil.rmtree(val_label_dir)\n",
    "        os.makedirs(val_label_dir)\n",
    "        \n",
    "        def tmp_train_path(f):\n",
    "            base_filename = os.path.basename(f)\n",
    "            return os.path.join(train_label_dir, base_filename)\n",
    "        def tmp_val_path(f):\n",
    "            base_filename = os.path.basename(f)\n",
    "            return os.path.join(val_label_dir, base_filename)\n",
    "        \n",
    "        map(lambda f: shutil.copyfile(f, tmp_train_path(f)), train_set)\n",
    "        map(lambda f: shutil.copyfile(f, tmp_val_path(f)), val_set)\n",
    "        \n",
    "        n_train_files += len(train_set)\n",
    "        n_val_files += len(val_set)\n",
    "                 \n",
    "    print 'Found {} files for train set'.format(n_train_files)\n",
    "    print 'Found {} files for validaiton set'.format(n_val_files)\n",
    "                 \n",
    "    return train_dir, val_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'melspectrograms'\n",
    "batch_size = 40\n",
    "epochs = 150\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "input_tensor = Input(shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure training and validation data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dir = '../hackathon_dataset/{}/train'.format(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3716 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# training generator configuration\n",
    "training_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "training_generator = training_datagen.flow_from_directory(\n",
    "    training_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_dir = '../hackathon_dataset/{}/validation'.format(data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1219 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# validation generator configuration\n",
    "validation_datagen = image.ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_training_samples = 3716\n",
    "nb_validation_samples = 1219\n",
    "n_classes = len(os.listdir(training_data_dir)) - 1\n",
    "class_labels = os.listdir(training_data_dir)[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'vgg16'\n",
    "pretrained_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "print('Model loaded')\n",
    "print pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg16 contain 19 layers\n"
     ]
    }
   ],
   "source": [
    "print 'vgg16 contain {} layers'.format(len(pretrained_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_layers_to_freeze = len(pretrained_model.layers) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_to_freeze = len(pretrained_model.layers) - 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 3,211,650\n",
      "Trainable params: 3,211,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=pretrained_model.output_shape[1:]))\n",
    "top_model.add(Dense(128, activation='relu'))\n",
    "top_model.add(Dropout(0.6))\n",
    "top_model.add(Dense(n_classes, activation='softmax'))\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine base model with top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 2)                 3211650   \n",
      "=================================================================\n",
      "Total params: 17,926,338\n",
      "Trainable params: 5,571,458\n",
      "Non-trainable params: 12,354,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# top_model.load_weights('bootlneck_fc_model.h5')\n",
    "model = Model(inputs=pretrained_model.input, outputs=top_model(pretrained_model.output))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('models/json_models'):\n",
    "    os.makedirs('models/json_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics, optimizers\n",
    "\n",
    "def top_5_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "\n",
    "for layer in model.layers[:num_layers_to_freeze]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# regualr SGD\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True), \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "model_filename = \"models/json_models/audioset_nesterov_{}_{}_{}_frozen_layers_dropout_60pct.json\"\\\n",
    "                    .format(model_name, data_source, num_layers_to_freeze)\n",
    "with open(model_filename, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('models/weights'):\n",
    "    os.makedirs('models/weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 5.5587 - acc: 0.5984Epoch 00000: val_acc improved from -inf to 0.61578, saving model to vgg16_melspec_weights_freeze_13_base_layers.best.hdf5\n",
      "92/92 [==============================] - 51s - loss: 5.5619 - acc: 0.5976 - val_loss: 6.1930 - val_acc: 0.6158\n",
      "Epoch 2/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 4.9664 - acc: 0.6118Epoch 00001: val_acc improved from 0.61578 to 0.61662, saving model to vgg16_melspec_weights_freeze_13_base_layers.best.hdf5\n",
      "92/92 [==============================] - 47s - loss: 4.9491 - acc: 0.6127 - val_loss: 6.1793 - val_acc: 0.6166\n",
      "Epoch 3/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 5.0400 - acc: 0.6132Epoch 00002: val_acc did not improve\n",
      "92/92 [==============================] - 45s - loss: 5.0403 - acc: 0.6125 - val_loss: 6.2476 - val_acc: 0.6124\n",
      "Epoch 4/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 4.9691 - acc: 0.6117Epoch 00003: val_acc did not improve\n",
      "92/92 [==============================] - 45s - loss: 4.9694 - acc: 0.6116 - val_loss: 6.2203 - val_acc: 0.6141\n",
      "Epoch 5/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 5.0531 - acc: 0.6068Epoch 00004: val_acc did not improve\n",
      "92/92 [==============================] - 43s - loss: 5.0605 - acc: 0.6070 - val_loss: 6.2887 - val_acc: 0.6098\n",
      "Epoch 6/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 4.8807 - acc: 0.6164Epoch 00005: val_acc improved from 0.61662 to 0.63104, saving model to vgg16_melspec_weights_freeze_13_base_layers.best.hdf5\n",
      "92/92 [==============================] - 43s - loss: 4.8815 - acc: 0.6168 - val_loss: 5.9469 - val_acc: 0.6310\n",
      "Epoch 7/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 5.1179 - acc: 0.6127Epoch 00006: val_acc did not improve\n",
      "92/92 [==============================] - 43s - loss: 5.1117 - acc: 0.6134 - val_loss: 6.3297 - val_acc: 0.6073\n",
      "Epoch 8/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 5.0306 - acc: 0.6142Epoch 00007: val_acc did not improve\n",
      "92/92 [==============================] - 43s - loss: 5.0380 - acc: 0.6143 - val_loss: 6.1930 - val_acc: 0.6158\n",
      "Epoch 9/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 5.1183 - acc: 0.6099Epoch 00008: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 5.1127 - acc: 0.6101 - val_loss: 6.2066 - val_acc: 0.6149\n",
      "Epoch 10/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 5.0894 - acc: 0.6143Epoch 00009: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 5.0794 - acc: 0.6144 - val_loss: 6.0562 - val_acc: 0.6243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1aa829af90>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from time import time\n",
    "\n",
    "# set up log files for tensorboard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/vgg16_{}_layers_frozen\".format(num_layers_to_freeze))\n",
    "\n",
    "# configure early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"vgg16_melspec_weights_freeze_{}_base_layers.best.hdf5\".format(num_layers_to_freeze)\n",
    "best_model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [best_model_checkpoint, tensorboard, early_stopping]\n",
    "\n",
    "model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=nb_training_samples/batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples/batch_size,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate and plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAFfCAYAAACMWD3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyzAnaTOzDHOSNjPLsP8HKxHxh07wY1AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ab259a250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for label in class_labels:\n",
    "    file_list = os.listdir(validation_data_dir + '/' + label)\n",
    "    for file_name in file_list:\n",
    "        img_path = validation_data_dir + '/' + label + '/' + file_name\n",
    "        \n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)* 1./255\n",
    "        \n",
    "        preds = model.predict(x)[0]\n",
    "        \n",
    "        y_true.append(label)\n",
    "        y_pred.append(class_labels[np.argmax(preds)])\n",
    "        \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, sorted(class_labels), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 7.0297 - acc: 0.5602Epoch 00000: val_acc improved from -inf to 0.61408, saving model to vgg16_melspec_weights_freeze_17_base_layers.best.hdf5\n",
      "92/92 [==============================] - 51s - loss: 6.9927 - acc: 0.5625 - val_loss: 6.2203 - val_acc: 0.6141\n",
      "Epoch 2/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.3180 - acc: 0.6075Epoch 00001: val_acc improved from 0.61408 to 0.61493, saving model to vgg16_melspec_weights_freeze_17_base_layers.best.hdf5\n",
      "92/92 [==============================] - 47s - loss: 6.3238 - acc: 0.6072 - val_loss: 6.2066 - val_acc: 0.6149\n",
      "Epoch 3/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2545 - acc: 0.6119Epoch 00002: val_acc improved from 0.61493 to 0.61578, saving model to vgg16_melspec_weights_freeze_17_base_layers.best.hdf5\n",
      "92/92 [==============================] - 49s - loss: 6.2610 - acc: 0.6115 - val_loss: 6.1930 - val_acc: 0.6158\n",
      "Epoch 4/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.1598 - acc: 0.6172Epoch 00003: val_acc improved from 0.61578 to 0.62256, saving model to vgg16_melspec_weights_freeze_17_base_layers.best.hdf5\n",
      "92/92 [==============================] - 48s - loss: 6.1673 - acc: 0.6168 - val_loss: 6.0836 - val_acc: 0.6226\n",
      "Epoch 5/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2757 - acc: 0.6104Epoch 00004: val_acc did not improve\n",
      "92/92 [==============================] - 46s - loss: 6.2754 - acc: 0.6103 - val_loss: 6.2613 - val_acc: 0.6115\n",
      "Epoch 6/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.1796 - acc: 0.6164Epoch 00005: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 6.1826 - acc: 0.6162 - val_loss: 6.2340 - val_acc: 0.6132\n",
      "Epoch 7/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2487 - acc: 0.6113Epoch 00006: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 6.2465 - acc: 0.6114 - val_loss: 6.1109 - val_acc: 0.6209\n",
      "Epoch 8/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2044 - acc: 0.6148Epoch 00007: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 6.2202 - acc: 0.6138 - val_loss: 6.3297 - val_acc: 0.6073\n",
      "Epoch 9/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2741 - acc: 0.6102Epoch 00008: val_acc improved from 0.62256 to 0.62256, saving model to vgg16_melspec_weights_freeze_17_base_layers.best.hdf5\n",
      "92/92 [==============================] - 46s - loss: 6.2716 - acc: 0.6104 - val_loss: 6.0836 - val_acc: 0.6226\n",
      "Epoch 10/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2545 - acc: 0.6112Epoch 00009: val_acc did not improve\n",
      "92/92 [==============================] - 46s - loss: 6.2391 - acc: 0.6122 - val_loss: 6.2476 - val_acc: 0.6124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ab01b5f90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True), \n",
    "#                      loss='categorical_crossentropy', \n",
    "#                      metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adagrad(lr=0.01, epsilon=1e-6), \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "model_filename = \"models/json_models/audioset_nesterov_{}_{}_{}_frozen_layers_dropout_60pct.json\"\\\n",
    "                    .format(model_name, data_source, num_layers_to_freeze)\n",
    "with open(model_filename, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "if not os.path.exists('models/weights'):\n",
    "    os.makedirs('models/weights')\n",
    "    \n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from time import time\n",
    "\n",
    "# set up log files for tensorboard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/vgg16_{}_layers_frozen\".format(num_layers_to_freeze))\n",
    "\n",
    "# configure early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"vgg16_melspec_weights_freeze_{}_base_layers.best.hdf5\".format(num_layers_to_freeze)\n",
    "best_model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [best_model_checkpoint, tensorboard, early_stopping]\n",
    "\n",
    "model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=nb_training_samples/batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples/batch_size,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAFfCAYAAACMWD3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbWaWYv8fprn5O1IsHXcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b187a1090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for label in class_labels:\n",
    "    file_list = os.listdir(validation_data_dir + '/' + label)\n",
    "    for file_name in file_list:\n",
    "        img_path = validation_data_dir + '/' + label + '/' + file_name\n",
    "        \n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)* 1./255\n",
    "        \n",
    "        preds = model.predict(x)[0]\n",
    "        \n",
    "        y_true.append(label)\n",
    "        y_pred.append(class_labels[np.argmax(preds)])\n",
    "        \n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plot_confusion_matrix(cm, sorted(class_labels), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2316 - acc: 0.6124Epoch 00000: val_acc improved from -inf to 0.60984, saving model to vgg16_melspec_weights_freeze_17_base_layers.best.hdf5\n",
      "92/92 [==============================] - 50s - loss: 6.2383 - acc: 0.6120 - val_loss: 6.2887 - val_acc: 0.6098\n",
      "Epoch 2/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2294 - acc: 0.6136Epoch 00001: val_acc improved from 0.60984 to 0.62256, saving model to vgg16_melspec_weights_freeze_17_base_layers.best.hdf5\n",
      "92/92 [==============================] - 46s - loss: 6.2230 - acc: 0.6139 - val_loss: 6.0836 - val_acc: 0.6226\n",
      "Epoch 3/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2535 - acc: 0.6110Epoch 00002: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 6.2643 - acc: 0.6104 - val_loss: 6.2613 - val_acc: 0.6115\n",
      "Epoch 4/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2176 - acc: 0.6135Epoch 00003: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 6.2464 - acc: 0.6117 - val_loss: 6.1656 - val_acc: 0.6175\n",
      "Epoch 5/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2619 - acc: 0.6107Epoch 00004: val_acc did not improve\n",
      "92/92 [==============================] - 46s - loss: 6.2770 - acc: 0.6098 - val_loss: 6.1519 - val_acc: 0.6183\n",
      "Epoch 6/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.1790 - acc: 0.6164Epoch 00005: val_acc did not improve\n",
      "92/92 [==============================] - 46s - loss: 6.1907 - acc: 0.6157 - val_loss: 6.1793 - val_acc: 0.6166\n",
      "Epoch 7/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2605 - acc: 0.6114Epoch 00006: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 6.2581 - acc: 0.6115 - val_loss: 6.1930 - val_acc: 0.6158\n",
      "Epoch 8/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.1480 - acc: 0.6183Epoch 00007: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 6.1469 - acc: 0.6184 - val_loss: 6.1109 - val_acc: 0.6209\n",
      "Epoch 9/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.2731 - acc: 0.6103Epoch 00008: val_acc improved from 0.62256 to 0.62426, saving model to vgg16_melspec_weights_freeze_17_base_layers.best.hdf5\n",
      "92/92 [==============================] - 44s - loss: 6.2663 - acc: 0.6107 - val_loss: 6.0562 - val_acc: 0.6243\n",
      "Epoch 10/10\n",
      "91/92 [============================>.] - ETA: 0s - loss: 6.3107 - acc: 0.6085Epoch 00009: val_acc did not improve\n",
      "92/92 [==============================] - 44s - loss: 6.3297 - acc: 0.6073 - val_loss: 6.1656 - val_acc: 0.6175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1aa8386890>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import metrics, optimizers\n",
    "\n",
    "def top_5_accuracy(y_true, y_pred):\n",
    "    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)\n",
    "\n",
    "for layer in model.layers[:num_layers_to_freeze]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# regualr SGD\n",
    "model.compile(optimizer=optimizers.SGD(lr=1e-5, momentum=0.5, decay=1e-8, nesterov=True), \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "model_filename = \"models/json_models/audioset_nesterov_{}_{}_{}_frozen_layers_dropout_60pct.json\"\\\n",
    "                    .format(model_name, data_source, num_layers_to_freeze)\n",
    "with open(model_filename, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "model_filename = \"models/json_models/audioset_nesterov_{}_{}_{}_frozen_layers_dropout_60pct.json\"\\\n",
    "                    .format(model_name, data_source, num_layers_to_freeze)\n",
    "with open(model_filename, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "if not os.path.exists('models/weights'):\n",
    "    os.makedirs('models/weights')\n",
    "    \n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from time import time\n",
    "\n",
    "# set up log files for tensorboard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/vgg16_{}_layers_frozen\".format(num_layers_to_freeze))\n",
    "\n",
    "# configure early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15)\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"vgg16_melspec_weights_freeze_{}_base_layers.best.hdf5\".format(num_layers_to_freeze)\n",
    "best_model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [best_model_checkpoint, tensorboard, early_stopping]\n",
    "\n",
    "model.fit_generator(\n",
    "    training_generator,\n",
    "    steps_per_epoch=nb_training_samples/batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples/batch_size,\n",
    "    callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
